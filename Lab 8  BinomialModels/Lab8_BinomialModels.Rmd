---
title: 'Lab 8: Binomial Models in R'
author: "Eric Parajon"
header-includes:
- \usepackage{enumerate}
- \usepackage{graphicx}
output:
  html_document:
    df_print: paged
---

Today's lab has been adapted from code by Chelsea Estancona, Isabel Laterzo, and Simon Hoellerbauer.
```{r setup, include=T}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)

rm(list=ls()) # clear workspace
#setwd("____") # change to wherever you saved the data
set.seed(1234) # set seed for replication

#Load in packages
pacman::p_load(tidyverse,
               rio,#for importing data
               arm)

```


# Binomial Models

Today we'll work through a fairly standard problem: you have a dichotomous dependent variable and a set of independent variables, and you want to estimate a model. Let's walk through a full example.

Load the `Lab_8_data.dta` file. These are data from a previous project (Chelsea Estancona ('18)'s) about paramilitary groups in Colombia. Our DV is a dichotomous variable coding paramilitary presence in certain municipalities.


```{r}
colombia <- rio::import("Lab_8_data.dta")

```

Let's plot our DV. This is always a good practice for *all* variables (independent or dependent) in your work. 

```{r}
ggplot(colombia, aes(x = as.factor(AUC))) +
  geom_bar() +
  labs(x = 'Autodefensas Unidas de Colombia Presence') +
  theme_bw()


```

Note that plotting in this way can also give us information about missingness (which there's a lot of on this variable). Remember - what does R do with our missing data if we leave it to handle it on its own?

Now we're ready to put together a simple model. 

```{r}
#for a logit model, how should we specify family?

m1 <- glm(AUC ~ tribut_2_log + tribut_2_log_sq + pop_attacks + disbogota +
            drugs + pop_log, data=colombia, family = __________)

summary(m1)
```


If we wanted to use a probit link: 


```{r}
#for a probit model, how should we specify family?

m2 <- glm(AUC ~ ., data = colombia, family = ___________)
#what is the . doing above?
summary(m2)
```

The sign (and generally, significance) of our coefficient estimates remain the same. The values differ due to these link functions. 

This is all very well and good, but how useful are the coefficient estimates? How do we interpret them? 

We might want to use our model to estimate predicted probabilities, as this is a readily-understood measure of how changes in our independent variable affect the probability of observing a certain outcome. In doing so, we'll want to think about a 'hypothetical case' for which we want to predict: for example, here, we'll calculate the predicted probability of the United Self-Defenses of Colombia or Autodefensas Unidas de Colombia (AUC) presence in a municipality with the mean tax income, mean attacks on population, mean distance from the capitol, drug crops, and the average population. *Note*: This is the so-called average case approach.

```{r}
## calculate value of the linear predictor for this variable profile
linpred <- as.numeric(with(colombia, coef(m1)[1] +
                             coef(m1)[2] * mean(tribut_2_log, na.rm = TRUE) +
                             coef(m1)[3] * mean(tribut_2_log, na.rm = TRUE)^2 +
                             coef(m1)[4] * mean(pop_attacks, na.rm = TRUE) +
                             coef(m1)[5] * mean(disbogota, na.rm = TRUE) +
                             coef(m1)[6] * (1) + #could set this to its mode
                             coef(m1)[7] * mean(pop_log, na.rm = TRUE)))


#let's take a look!
stats::plogis

## plogis lets us transform our log-odds to the range (0,1) - now interpretable
## as a standard probability

plogis(linpred)
```
We can also do this using the 'predict' function: 

```{r}
## create a 'new data' frame: we want to predict the probability for a hypothetical situation.
new_data <- with(colombia, data.frame(tribut_2_log = mean(tribut_2_log, na.rm = TRUE),
                                      tribut_2_log_sq = mean(tribut_2_log, na.rm = TRUE)^2,
                                      pop_attacks = mean(pop_attacks, na.rm = TRUE),
                                      disbogota = mean(disbogota, na.rm = TRUE),
                                      drugs = c(0, 1),
                                      pop_log = mean(pop_log, na.rm = TRUE)))
## note above that I include both possible values for drugs. the 'data.frame()'
## command is flexible and will intelligently duplicate the other values

#Here use predict()
predict(_____, newdata = ________, type = 'response') #The type="response" option tells R to output probabilities of the form P(Y = 1|X)
```

What if we were interested in a *range* of values' predicted probability? We could modify our newdata frame and our predict() function to allow for this. 

```{r}
min_tax <- min(colombia$tribut_2_log, na.rm = TRUE)
max_tax <- max(colombia$tribut_2_log, na.rm = TRUE)
min_tax_2 <- min(colombia$tribut_2_log_sq, na.rm = TRUE)
max_tax_2 <- max(colombia$tribut_2_log_sq, na.rm = TRUE)

new_data_2 <- with(colombia,
                 data.frame(tribut_2_log = seq(from = min_tax, to = max_tax,
                                               length.out = 100),
                            tribut_2_log_sq = seq(from = min_tax_2, to = max_tax_2,
                                                  length.out = 100),
                            pop_attacks = mean(pop_attacks, na.rm = TRUE),
                            disbogota = mean(disbogota, na.rm = TRUE),
                            drugs = 1, pop_log = mean(pop_log, na.rm = TRUE)))

new_data_3 <- with(colombia,
                 data.frame(tribut_2_log = seq(from = min_tax, to = max_tax,
                                               length.out = 100),
                            tribut_2_log_sq = seq(from = min_tax_2, to = max_tax_2,
                                                  length.out = 100),
                            pop_attacks = mean(pop_attacks, na.rm = TRUE),
                            disbogota = mean(disbogota, na.rm = TRUE),
                            drugs = 0, pop_log = mean(pop_log, na.rm = TRUE)))


predict(m1, newdata = new_data_2, type = 'response') # what is the length of this output?
predict(m2, newdata = new_data_3, type = 'response')

#we can calculate the logit predicted probs by hand by doing 1/(1 + exp(-linpred))
#How could we calculate this for probit?

#We can use pnorm! (this is, after all, the difference between the logit and probit)
all(predict(m2, newdata = new_data_3, type = "response") ==
      pnorm(as.matrix(cbind(1, new_data_3)) %*% coef(m2)))
```

Note that in this case, it is perfectly ok to vary the tax variable and the the squared tax value from its min to its max, as the square roots of the minimum and maximum squared are equal to the minimum and maximum (unless for some reason you have missingness in one variable at the max and min, which should be unlikely).

We know from the numeric output that logit and probit links produce different coefficient estimates, but how do these differences translate into predicted probabilities? We can plot the predicted probabilities from each model to quickly inspect these differences.

```{r}
## generate predicted probabilities for municipality with drugs and all other
## variables at their means
pred_output <- data.frame(Logit = predict(_____, newdata = _______, type = _______),
                          Probit = predict(____, newdata = ________, type = ______),
                          tax = new_data_2$tribut_2_log)

plot_pred1 <- gather(pred_output, key = "link", value = "Pred_Probs", -tax)

## plot predicted probabilities
ggplot(data = plot_pred1, aes(x = tax, y = Pred_Probs, color = link)) +
  geom_line() +
  scale_color_discrete(name = 'Link Function') +
  labs(x = 'Tax Revenue', y = 'Predicted Probability') +
  theme_bw()+
  geom_rug(data = colombia, aes(x = tribut_2_log), 
           size = 1, inherit.aes = F) #adding rug plot what is this showing us? Why is there a divergence?

```

# Simulation

Simulation strikes again! This time around, we will do similar things, but with non-Normal outcomes, where simulations are even more helpful.

Today, we're going to simulate predicted probabilities for a model with an interaction term, use the distribution of these simulated probabilities to define confidence intervals, and plot our results, using both the average case and the observed-case approaches.

## Using Average-Case Approach

The following should all look familiar:
```{r}
## number of simulations for predicted probabilities
N_sim <- 1000

## extract beta hats and construct vcv from our first model
betas <- m1$coef
vcv <- vcov(m1)

## use the mvrnorm function with the betas, vcv, and # of simulations to simulate
## parameter estimates. will have 1,000 estimates of each beta
beta_sims <- mvrnorm(N_sim, betas, vcv)

## create a vector that is a sequence of 100 points, evenly spaced between the
## lowest and highest observed values of tax income in the data set. we have to
## do this for the (tax^2) variable, too!
tax_min <- with(colombia, min(tribut_2_log, na.rm = TRUE))
tax_max <- with(colombia, max(tribut_2_log, na.rm = TRUE))
tax_vec <- seq(from = tax_min, to = tax_max, length = 100)
trans_vec <- (tax_vec^2)
## these will be the x values over which we can plot the predicted probability.
## we're interested in how the predicted probability of AUC presence varies over
## the municipalities' values of tax revenue

## create a hypothetical independent variable as before: mean attacks on population,
## mean distance from the capitol, drug crops set to 1, and the average population.
hyp <- with(colombia, data.frame(intercept = 1, 
                                 tribut_2_log = tax_vec,
                                 tribut_2_log_sq = trans_vec,
                                 pop_attacks = mean(pop_attacks, na.rm = TRUE),
                                 disbogota = mean(disbogota, na.rm = TRUE),
                                 drugs = 1,
                                 pop_log = mean(pop_log, na.rm = TRUE)))

#We could also have done this using model.matrix()

## create an empty matrix of values to fill with simulated predicted probabilities
pp_sims <- matrix(NA, nrow = N_sim, ncol = length(tax_vec))
#Using a for() loop to fill wth simulated pred. probs
for(i in 1:N_sim) {
  
  pp_sims[i, ] <- plogis(as.matrix(hyp) %*% beta_sims[i, ])
  
}

#we could also do this with less code:
pp_sims2 <- plogis(as.matrix(hyp) %*% t(beta_sims))

dim(pp_sims)
dim(pp_sims2)

all(t(pp_sims) == pp_sims2)


```

We're not going to worry a lot about confidence intervals today, but below is the code for them as well. 

```{r}

## CIs
pe <- apply(pp_sims, 2, mean)
lo <- apply(pp_sims, 2, quantile, prob = .025)
hi <- apply(pp_sims, 2, quantile, prob = .975)

sim_output <- data.frame(tax = hyp[, 2], pe, lo, hi)

ggplot(sim_output, aes(x = tax, y = pe, ymin = lo, ymax = hi)) +
  geom_ribbon(aes(fill = '95% Confidence Interval (Simulation)'), alpha = .5) +
  geom_line(aes(color = 'Predicted Probability Over Values of Municipal Revenue'),
            size = 1) +
  labs(x = 'Revenue', y = 'Probability of Paramilitary Presence') +
  theme_bw() +
  theme(legend.title = element_text(), legend.position = 'bottom',
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank()) +
  scale_fill_manual(values = 'steelblue3', name = '') +
  scale_color_manual(values = 'black', name = '')
```

## Using Observed-Case Approach - Average Predicted Effects

The code above created a hypothetical set of cases in which we might be interested, but what if we wanted more of an average effect? To this end, we can code and plot an 'average predictive effect' that covers the values of our key variable (we still generate predicted probabilities 'along' these values) and all possible values of the other variables in our dataset.

```{r, cache = TRUE}
## create a 'temporary' dataset - bind a 1 for the intercept and omit missingness
temporary <- model.matrix( ~ tribut_2_log + tribut_2_log_sq + pop_attacks + 
                             disbogota + drugs + pop_log, data = colombia)

## create an object and store predicted probabilities
## look into the ?map_dfc function from the purrr package (part of the tidyverse)

#note this will take a few minutes
pp <- purrr::map_dfc(tax_vec, function(j) {
    temporary[, "tribut_2_log"] <- j
    temporary[, "tribut_2_log_sq"] <- j^2
    
    pp <- plogis(temporary %*% t(beta_sims))
    
    #getting mean for each set of betas
    pp <- apply(pp, 2, mean)
  
    return(pp)
    })


## find the mean (average predictive effect) for each observation, and bind with
## confidence measures (interval) 
plotdat <- t(apply(pp, 2, function(x) { # transposing w/ t() puts data into a column
    c(M = mean(x), quantile(x, c(0.025, 0.975)))
}))

# add x vector and convert to data frame
plotdat <- data.frame(tax_vec, plotdat)

# better names and show the first few rows (to check)
colnames(plotdat) <- c('tax', 'pe', 'lo', 'hi')
head(plotdat)

#now let's rowbind in the average-case predicted probabilities, so that we can 
#compare them
plotdat <- rbind(plotdat, sim_output) %>% 
  mutate(Approach = c(rep("Observed-Case",length(tax_vec)),
                      rep("Average-Case", length(tax_vec))))

## plot of predicted probabilities
ggplot(plotdat, aes(x = tax, y = pe, ymin = lo, ymax = hi, color = Approach,
                    fill = Approach)) +
  geom_ribbon(alpha = .25) +
  geom_line() +
  labs(x = 'Tax Revenue', y = 'Predicted Probability') +
  ylim(c(0, 1)) +
  theme_bw()
```

# Exercise

+ Read in the data 'turnout.csv.' Fit a logit model that predicts voting based on race, education and income. 

+ Now, fit a second model that predicts voting based on race, education, income, and age. Assume that you've hypothesized that age has a curvilinear relationship with voting turnout, such that lower ages and higher ages are less likely to vote. Include this transformed variable.

+ Compare the model fit of these two options using lrtest, AIC, and BIC. Which do you choose as the better fitting model?

+ Average-Case Approach: Simulate and plot predicted probabilities over the range of **age**, holding all other variables at their mean, for the second model. Plot this.

+ Observed-Case Approach: Generate an average predicted effect over the observed values of **income** for the first model. Plot this too.

```{r}

#Load in packages
pacman::p_load(lmtest)

turnout<-import("turnout.csv")
#Fit the two models
  #m1
m1 <- glm(vote ~ race + educate + income, turnout, family =______)

  #m2
m2 <- glm(vote ~ race + educate + income + poly(age, 2, raw = T), turnout, 
         family =______))


#Model fit
lrtest(______)
AIC()
BIC()
AIC()
BIC()

#Which is better?

# Average-Case Approach

#When we combine the average-case approach with simulation, we create a hypothetical design matrix, where we hold all continuous variables at their mean or another justifiable value, and then let the predictor of interest vary along some range. 


sim_dat <- with(______, data.frame(intercept = 1, race = 1,
                                    educate = mean(educate), income = mean(income),
                                    age = seq(min(age), max(age), length.out = 100),
                                    age2 = (seq(min(age), max(age), length.out = 100))^2))

sim_betas <- mvrnorm(______,______, vcov(m2))

sim_pp <- apply(sim_betas, 1, function(x) plogis(as.matrix(sim_dat) %*% x))

sim_gg <- data.frame(age = ______, pe = apply(sim_pp, 1, mean),
                     lo = apply(sim_pp, 1, quantile, probs = .025),
                     hi = ______)


ggplot(sim_gg, aes(x = age, y = pe, ymin = lo, ymax = hi)) +
        ______

# Observed-Case Approach

#When taking the observed-case approach (see Hanmer and Kalkan (2013) for why this is the preferable approach) and using simulation to get confidence intervals, we have to do things slightly differently. Specifically, we will have to take an addition mean.

temporary <- model.matrix(m1)

#getting sim betas for m1
sim_betas_m1 <- mvrnorm(______,______,vcov(m1))

#getting range of income
income_vec <- seq(from = min(turnout$income),to=____),
                  length.out = 100)


#Here we use `map_dfc` function from `purrr` (part of the tidyverse) to we apply the function to each element in the vector, and then (because the function returns a vector) we get a dataframe in as output.


#This is doing a few things: 
#1. takes the temporary design matrix we created above, and then replaces *all* of the values of our predictor of interest with one value (taken from the hypothetical value vector).

#2. We then matrix multiply this new design matrix, with all actual values of our predictor of interest replaced by one hypothetical value of our predictor interest and with all the other values held at their observed values, by our simulated betas.

#3.  We then take the mean across the columns (`margins = 2`) because different columns represent different predicted probabilities, for each of the observations in our temporary design matrix, when we use different betas and when our predictor of interest has been replaced with one value.

#4. The call to `map_dfc` then returns a dataframe that has 1000 rows and 100 columns (1 column for each value of our hypothetical value vector).

pp <- map_dfc(income_vec, function(j) {
    temporary[, "income"] <- j
    
    pp <- plogis(temporary %*% t(sim_betas_m1))
    
    pp <- apply(pp, 2, mean)
  
    return(pp)
    })


#Pulling it all into a df and getting the mean of predicted values for each value of our hypothetical value vector, and then use the `quantile` with a `probs` argument equal to the bounds of our desired confidence interval (for example, if we want a 95% confidence interval, we will do `quantile(x, probs = c(0.025, 0.975))`)

plotdat <- t(apply(pp, 2, function(x) { # transposing w/ t() puts data into a column
    c(M = mean(x), quantile(x, c(0.025, 0.975)))
}))

plotdat <- data.frame(plotdat, ______)


#We can then use these data to plot the mean predicted probability and our confidence bands.


colnames(______) <- c('pe', 'lo', 'hi', 'income')

ggplot(plotdat, aes(x = income, y = pe, ymin = lo, ymax = hi)) +
          ______


```


