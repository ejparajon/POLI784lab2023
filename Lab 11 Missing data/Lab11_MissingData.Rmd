---
title: "Lab 11 - Missing Data and Imputation"
author: "Eric Parajon"
header-includes:
- \usepackage{enumerate}
- \usepackage{graphicx}
output:
  html_document:
    df_print: paged
---

This week we will be learning ways to handle missing data. Often times you will come across, or collect, data with a significant amount of missingness across variables of interest. If the amount of data is quite small, typically you can ignore it. However, you will likely come across cases where your data has a pretty significant amount of missingness. A common rule of thumb for "too much" missingness - indicating you need to deal with it in some way - is if > 5% of your data is missing. 

Today, we will be examining how we would deal with data that has a significant amount of missingness. We will walk through listwise deletion, mean/median/mode substitution, and something called "imputation." 

**Data!**
First, let's get our data set up. 
```{r}
#clear global environment
rm(list=ls())

#load in iris data
data_clean <- iris
summary(data_clean)

#Checking number of NAs
sum(is.na(data_clean))

#here's our "true model" for future reference
model_true <- lm(Sepal.Length~ Sepal.Width+Petal.Length+Petal.Width, data = data_clean)

#lets copy this df and then add some missingness
data_miss <- data_clean
data_miss[52:59,1] <- rep(NA,2)
data_miss[6:27,2] <- rep(NA,2)
data_miss[102:119,4] <- rep(NA,2)
data_miss[35:50,3] <- rep(NA,2)
summary(data_miss) #check out those *~* NAs ~*~

sum(is.na(data_miss))

```

Alright, let's take a look at those NA's more deeply
```{r}
#what does this do?
is.na(data_miss$Sepal.Width)

#and this?
which(is.na(data_miss$Sepal.Width))

#and this?
sum(is.na(data_miss$Sepal.Width))

#apply this to other variables!

#An easy way to look at this across the whole DF
colSums(is.na(data_miss))
```

**Listwise Deletion**
Some people just delete the observations with missing values. Although this is definitely a viable approach, depending on how much missing data you have, you might be getting rid of a lot of information!

Below, use the function `na.omit()` to get rid of observations with missing values, then repeat the above `lm()` model with this new data.
```{r, eval = FALSE}
# subset with complete.cases to get complete cases
data_listwise <- na.omit(data_miss)
summary(data_listwise)

#let's create an lm with this model to compare to later iterations

model_listwise <- lm(Sepal.Length~ Sepal.Width+Petal.Length+Petal.Width, data = data_listwise)

summary(model_listwise)
```


**Mean/Median Recoding**

Alternatively, we can replace missing values with other values - such as the mean, median, or mode. Mode is appropriate if you're dealing with categorical variables, but since we're dealing with continuous here, we'll use one of the others. 

Although this is a pretty easy approach, mean/median recoding decreases and changes the variance of your data. Especially in the case of time series data, this might not be great - we might be replacing a value with a mean of *all* the existing values, instead of one appropriate for the time period it belongs to! But, let's try it anyways.

```{r, eval = FALSE}
#make a copy of the data
data_recode <- data_miss

#uses if else statements to recode NA values as the mean of the rest of that column
data_recode$Sepal.Width <- ifelse(is.na(data_recode$Sepal.Width),
                            mean(data_recode$Sepal.Width, na.rm = TRUE),
                            data_recode$Sepal.Width)

data_recode$Petal.Length<- ifelse(is.na(data_recode$Petal.Length),
                            mean(data_recode$Petal.Length, na.rm = TRUE),
                            data_recode$Petal.Length)

data_recode$Petal.Width<- ifelse(is.na(data_recode$Petal.Width),
                            mean(data_recode$Petal.Width, na.rm = TRUE),
                            data_recode$Petal.Width)

data_recode$Sepal.Length <- ifelse(is.na(data_recode$Sepal.Length),
                            mean(data_recode$Sepal.Length, na.rm = TRUE),
                            data_recode$Sepal.Length)
                          
#summarize
summary(data_recode)


#linear model (same as above, but rename "model_recode")
model_recode <- lm(Sepal.Length~ Sepal.Width+Petal.Length+Petal.Width, data = data_recode)

summary(model_recode)
```

**Multiple Imputation**

Now multiple imputation, a super useful technique. First, we'll discuss `mice`. This package uses multivariate imputations to estimate missing values. What does this mean? Well, if a value is identified as missing, the package will then regress over the other variables and predict the various missing values. This is pretty cool. Further, using *multiple* imputations, or iterations of this process, instead of just one, helps us reduce uncertainty. 

Let's take a look!


```{r, eval = FALSE}
#Load in packages
pacman::p_load(mice,
               VIM,
               texreg) #Visualization and tables


#mice's df visualization
md.pattern(data_miss)

#vis using aggr() from VIM
aggr_plot <- aggr(data_miss, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(data_miss), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
#what is this showing us?

#MICE TIME
mice_data <- mice(data_miss, #call our data
                  m=5, #number of multiple imputations
                  maxit=50, #number of iterations
                  # method = ? mice will decide the most appropriate method based on your data
                  seed=500)

summary(mice_data)




#try this out with 25 iterations and 10 imputations
#select animputation method (try pmm) - what does it do differently?
mice_data_2 <- mice(data_miss, #call our data
                  m=_____, #number of multiple imputations
                  maxit=_____, #number of iterations
                  method = _____,
                  seed=500)


summary(mice_data_2)

```

So this is great, but then what do we do if we want to run a model? We have five data sets. One option is to pool the data this way:
```{r, eval = FALSE}
#pooling
model_mice <- with(mice_data,lm(Sepal.Length~ Sepal.Width+Petal.Length+Petal.Width))
summary(pool(model_mice))

#Using htmlreg package to display results in a table
htmlreg(pool(model_mice))

```
So mice is great. Let's also learn about Amelia II (my personal favorite, named after Amelia Earhart, because she is missing). Amelia is a little different because it assumes that your data is jointly distributed as multivariate normal. It uses the "expectation-maximization with bootstrapping" as an algorithm for imputation. The EM algorithm alternates between something called the expectation (E-step) and maximization (M-step) steps until it converges on values that were missing - it converges when the current and previous values are quite close (sounds a bit like Newton Raphson, no?). It brings in bootstraping by doing this process on multiple bootstrapped samples drawn from your original (and incomplete) data. 

Great, let's try it out. Examine the function by calling `?amelia()` - look at the different arguments.

```{r, message = FALSE, results='asis'}

#Load in packages
pacman::p_load(Amelia,
               lubridate,
               mice,
               texreg)


#impute
amelia_data <- amelia(x = data_miss,
                      noms="Species",
                       m = 5)


#let's run the model again, but this time using a for loop
models_amelia <- vector("list", 5)  #vector for our 5 newly imputed data sets


for(i in 1:5){
  models_amelia[[i]] <- lm(Sepal.Length~ Sepal.Width+Petal.Length+Petal.Width,
                        data=amelia_data$imputations[[i]]) #why do we index like this?
}

summary(pool(models_amelia))

#Putting into table
htmlreg(pool(models_amelia))

```

Compare how models from mice, Amelia, and the above methods perform to our true data:
```{r, eval = FALSE, results='asis'}
# Estimate models
mod <- list()
mod[['True']] <- model_true
mod[['Listwise deletion']] <- model_listwise
mod[['Recoding']] <- model_recode
mod[['Mice']] <- pool(model_mice)
mod[['Amelia']] <- pool(models_amelia)

htmlreg(mod)

```

# Exercise **On your own:**

Try Amelia again, but this time let's use more of its functionality. Read in data from the `africa` package and examine its missingness. Then, using Amelia, impute missing values. Note that the dataset is cross-sectional by country, time series by year, and should have the `gdp_pc` variable specified as logged.

After imputing the data, write a linear model that evaluates the effect of `infl`, `trade`, `civlib` and `population` on `gdp_pc`. Report the pooled results!

```{r, eval = FALSE}
library(Amelia)
data("africa") #read in

#explore missingness
apply(africa, 2, function(x) sum(is.na(x))) #missingness by column



#use Amelia to generate 5 imputed datasets
#use ts and cs so imputation algorithm knows which variables represent countries and years

africa_imp <- amelia(x = __________, 
                     cs = __________ 
                     ts = __________
                     logs = "gdp_pc")


models_africa <- vector(__)
for(i in 1:length(africa_imp$imputations)){
  __________________________________) 
}

#report results, including standard errors
htmlreg(pool(___))

#or if knitting to pdf
#texreg(pool(___))

```


